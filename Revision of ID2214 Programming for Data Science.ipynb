{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revision of ID2214 Programming for Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1], dtype='int64')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\"LKey\": list(\"acdef\"),\n",
    "\"A\":[0,0,0,1,1]})\n",
    "df2 = pd.DataFrame({\"RKey\": list(\"fedba\"),\n",
    "\"B\":[0,0,1,1,1]})\n",
    "df1.merge(df2,how=\"outer\",left_on=\"LKey\",right_on=\"RKey\")\n",
    "\n",
    "df1[\"A\"] = df1[\"A\"].astype(\"category\")\n",
    "df1[\"A\"].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction to Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 NumPy and pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Data preparation and evaluation\n",
    "\n",
    "* The instances need to be represented by fixed-length feature vectors\n",
    "* Information from test instances should not affect choice of data preparation and learning algorithms\n",
    "* there can be no missing numerical or categorical values\n",
    "* numerical features have to be normalized\n",
    "* curse of dimensinality has to be remedied by limiting the number of features\n",
    "\n",
    "\n",
    "\n",
    "### 3.1 Handling missing values\n",
    "remove/impute(mean, mode, nearest neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grade</th>\n",
       "      <th>award</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>c</td>\n",
       "      <td>bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id grade   award\n",
       "0  NaN   NaN     NaN\n",
       "1  2.0     b    gold\n",
       "2  3.0   NaN  silver\n",
       "3  4.0     c  bronze\n",
       "4  5.0   NaN     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grade</th>\n",
       "      <th>award</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>c</td>\n",
       "      <td>bronze</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id grade   award\n",
       "1  2.0     b    gold\n",
       "3  4.0     c  bronze"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grade</th>\n",
       "      <th>award</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>c</td>\n",
       "      <td>bronze</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id grade   award\n",
       "1  2.0     b    gold\n",
       "2  3.0   NaN  silver\n",
       "3  4.0     c  bronze"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"id\":[np.nan, 2, 3, 4, 5],\n",
    "                  \"grade\":[np.nan, \"b\", np.nan, \"c\", np.nan],\n",
    "                  \"award\":[np.nan, \"gold\", \"silver\", \"bronze\", np.nan]})\n",
    "display(df)\n",
    "# axis=\"index\" is default\n",
    "display(df.dropna(how=\"any\", axis=\"index\"))\n",
    "# drop when grade, award is all missing\n",
    "display(df.dropna(how=\"all\", subset=[\"grade\", \"award\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grade</th>\n",
       "      <th>award</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>c</td>\n",
       "      <td>bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id grade   award\n",
       "0  NaN   NaN     NaN\n",
       "1  2.0     b    gold\n",
       "2  3.0   NaN  silver\n",
       "3  4.0     c  bronze\n",
       "4  5.0   NaN     NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grade</th>\n",
       "      <th>award</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>e</td>\n",
       "      <td>iron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>e</td>\n",
       "      <td>silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>c</td>\n",
       "      <td>bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>e</td>\n",
       "      <td>iron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id grade   award\n",
       "0  NaN     e    iron\n",
       "1  2.0     b    gold\n",
       "2  3.0     e  silver\n",
       "3  4.0     c  bronze\n",
       "4  5.0     e    iron"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    3.5\n",
       "1    2.0\n",
       "2    3.0\n",
       "3    4.0\n",
       "4    5.0\n",
       "Name: id, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>grade</th>\n",
       "      <th>award</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>c</td>\n",
       "      <td>bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bronze</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id grade   award\n",
       "0  NaN   NaN  bronze\n",
       "1  2.0     b    gold\n",
       "2  3.0   NaN  silver\n",
       "3  4.0     c  bronze\n",
       "4  5.0   NaN  bronze"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# impute missing values\n",
    "\n",
    "df = pd.DataFrame({\"id\":[np.nan, 2, 3, 4, 5],\n",
    "                  \"grade\":[np.nan, \"b\", np.nan, \"c\", np.nan],\n",
    "                  \"award\":[np.nan, \"gold\", \"silver\", \"bronze\", np.nan]})\n",
    "display(df)\n",
    "# grade \"e\", \"award\" \"iron\"\n",
    "display(df.fillna(value={\"grade\": \"e\", \"award\": \"iron\"}))\n",
    "# impute with mean\n",
    "display(df[\"id\"].fillna(df[\"id\"].mean(), inplace=False))\n",
    "# impute with mode\n",
    "df[\"award\"].fillna(df[\"award\"].mode()[0], inplace=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Encoding features: from numerical to categorical (Discretization)\n",
    "\n",
    "equal width: each range is the same size  \n",
    "equal size: the same number of observed values fall into each range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00241647, 0.10305879, 0.20270466, 0.30235052, 0.40199639,\n",
       "       0.50164225, 0.60128812, 0.70093399, 0.80057985, 0.90022572,\n",
       "       0.99987158])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       (0.302, 0.402]\n",
       "1           (0.9, 1.0]\n",
       "2       (0.601, 0.701]\n",
       "3           (0.9, 1.0]\n",
       "4       (0.203, 0.302]\n",
       "            ...       \n",
       "95      (0.601, 0.701]\n",
       "96    (0.00242, 0.103]\n",
       "97      (0.302, 0.402]\n",
       "98      (0.402, 0.502]\n",
       "99      (0.103, 0.203]\n",
       "Name: values, Length: 100, dtype: category\n",
       "Categories (10, interval[float64]): [(0.00242, 0.103] < (0.103, 0.203] < (0.203, 0.302] < (0.302, 0.402] ... (0.601, 0.701] < (0.701, 0.801] < (0.801, 0.9] < (0.9, 1.0]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0     (0.9, inf]\n",
       "1     (0.9, inf]\n",
       "2     (0.9, inf]\n",
       "3     (0.9, inf]\n",
       "4     (0.9, inf]\n",
       "         ...    \n",
       "95    (0.9, inf]\n",
       "96    (0.9, inf]\n",
       "97    (0.9, inf]\n",
       "98    (0.9, inf]\n",
       "99    (0.9, inf]\n",
       "Name: values, Length: 100, dtype: category\n",
       "Categories (10, interval[float64]): [(-inf, 0.103] < (0.103, 0.203] < (0.203, 0.302] < (0.302, 0.402] ... (0.601, 0.701] < (0.701, 0.801] < (0.801, 0.9] < (0.9, inf]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# equal width: each range is the same size\n",
    "# one column of 100 random values\n",
    "df = pd.DataFrame({\"values\":np.random.rand(100)})\n",
    "res, bins = pd.cut(df[\"values\"], 10, retbins=True)\n",
    "display(bins)\n",
    "display(res)\n",
    "\n",
    "bins[0], bins[-1]=-np.inf, np.inf\n",
    "# bins\n",
    "df2 = pd.DataFrame({\"values\":np.ones(100)})\n",
    "\n",
    "# apply bins to new(test) data\n",
    "new_res = pd.cut(df2[\"values\"], bins)\n",
    "\n",
    "display(new_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eqaul sized binning will leads to bins for which the observed frequencies are nearly the same. It is more informative when being used before Naive-Bayes because the other one, equal-width binning will possibly put most of the observations into one bin, hence not allowing the learning algorithms to distinguish between the classes using discretized features.\n",
    "Equal-width binning may be helpful when we want to inspect how features are distributed(e.g. whether they form the normal distribution or not).(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.14096076, -1.17425366, -0.96843002, -0.61919754, -0.34723074,\n",
       "       -0.08324453,  0.1207581 ,  0.31629024,  0.62042679,  1.12610787,\n",
       "        1.93455278])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0     (-0.347, -0.0832]\n",
       "1        (0.121, 0.316]\n",
       "2         (0.316, 0.62]\n",
       "3         (0.62, 1.126]\n",
       "4      (-0.0832, 0.121]\n",
       "            ...        \n",
       "95     (-0.968, -0.619]\n",
       "96     (-1.174, -0.968]\n",
       "97     (-0.0832, 0.121]\n",
       "98       (0.121, 0.316]\n",
       "99     (-2.142, -1.174]\n",
       "Name: values, Length: 100, dtype: category\n",
       "Categories (10, interval[float64]): [(-2.142, -1.174] < (-1.174, -0.968] < (-0.968, -0.619] < (-0.619, -0.347] ... (0.121, 0.316] < (0.316, 0.62] < (0.62, 1.126] < (1.126, 1.935]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# equal-sized binning (using qcut)\n",
    "df = pd.DataFrame({\"values\": np.random.randn(100)})\n",
    "res, bins = pd.qcut(df[\"values\"],10,retbins=True)\n",
    "display(bins)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Encoding features: from categorical to numerical (One-Hot encoding)\n",
    "a new binary feature is created for each possible categorical value, and the new feature values for an instance are all assigned zero except for the feature corresponding to the categorical value appearing in the original row.\n",
    "\n",
    "e.g.\n",
    "one feature `color` has samples belonging to three categories `brown`, `red`, `green`\n",
    "now create three feature columns `color-brown`, `color-red`, `color-green` which only involve binary values. if samples belong to one feature, then they get 1, otherwise 0 in that feature column in their own rows.\n",
    "\n",
    "* notice feature explosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>color-green</th>\n",
       "      <th>color-red</th>\n",
       "      <th>color-yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  color-green  color-red  color-yellow\n",
       "0   1          1.0        0.0           0.0\n",
       "1   2          0.0        1.0           0.0\n",
       "2   3          0.0        0.0           1.0\n",
       "3   4          1.0        0.0           0.0\n",
       "4   5          0.0        1.0           0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>color-green</th>\n",
       "      <th>color-red</th>\n",
       "      <th>color-yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  color-green  color-red  color-yellow\n",
       "0   1          0.0        0.0           0.0\n",
       "1   2          0.0        0.0           0.0\n",
       "2   3          0.0        0.0           1.0\n",
       "3   4          1.0        0.0           0.0\n",
       "4   5          0.0        1.0           0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert category features of a dataframe into one_hot encoding\n",
    "def create_one_hot(df):\n",
    "    df_dict = dict()\n",
    "    one_hot = dict()\n",
    "    for i in df.columns:\n",
    "        if i!=\"ID\":\n",
    "            for c in sorted(df[i].unique()):\n",
    "                # generate one new feature column\n",
    "                df_dict[i+\"-\"+c] = [1.0 if k==c else 0.0 for k in df[i]]\n",
    "                if i not in one_hot:\n",
    "                    one_hot[i] = [c]\n",
    "                else:\n",
    "                    one_hot[i].append(c)\n",
    "    new_df = pd.DataFrame(df_dict)\n",
    "    new_df.insert(0, \"ID\", df[\"ID\"])\n",
    "    return new_df, one_hot\n",
    "\n",
    "def apply_one_hot(df, one_hot):\n",
    "    df_dict = {}\n",
    "    for col in one_hot:\n",
    "        for c in one_hot[col]:\n",
    "            df_dict[col+\"-\"+c] = [1.0 if c==k else 0.0 for k in df[col]]\n",
    "    \n",
    "    new_df = pd.DataFrame(df_dict)\n",
    "    new_df.insert(0, \"ID\", df[\"ID\"])\n",
    "    return new_df\n",
    "\n",
    "dataframe = pd.DataFrame({\"ID\":[1,2,3,4,5], \"color\":[\"green\",\"red\",\"yellow\",\"green\",\"red\"]})\n",
    "new_df, one_hot = create_one_hot(dataframe)\n",
    "display(new_df)\n",
    "\n",
    "test_dataframe = pd.DataFrame({\"ID\":[1,2,3,4,5], \"color\":[\"brown\",\"grey\",\"yellow\",\"green\",\"red\"]})\n",
    "test_new_df = apply_one_hot(test_dataframe, one_hot)\n",
    "display(test_new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Encoding features: normalization\n",
    "min-max **normalization**\n",
    "Attributes are often normalized\n",
    "to lie in a fixed range—usually from zero to one—by dividing all values by the\n",
    "maximum value encountered or by subtracting the minimum value and dividing\n",
    "by the range between the maximum and minimum values\n",
    "\n",
    "$xnorm = \\frac{xi-xmin}{xmax-xmin}$\n",
    "\n",
    "z-normalization (**standardization**)\n",
    "calculate the statistical mean and standard deviation of the attribute values, subtract the mean from each value, and divide the result by the standard deviation.\n",
    "\n",
    "$z = \\frac{xi-xmean}{SD}$\n",
    "\n",
    "and\n",
    "\n",
    "$SD = \\sqrt \\frac{\\sum_i^n (x_i - xmean)^2}{n}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min-max normalization:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.769140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.621250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.366393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.357488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.527664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.519710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.267881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.649702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.982436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      values\n",
       "0   0.769140\n",
       "1   0.219020\n",
       "2   0.621250\n",
       "3   0.366393\n",
       "4   0.357488\n",
       "..       ...\n",
       "95  0.527664\n",
       "96  0.519710\n",
       "97  0.267881\n",
       "98  0.649702\n",
       "99  0.982436\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-normalization:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.242194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.216455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.561687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.307243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.779873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.014525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.747559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.560561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.099646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      values\n",
       "0  -0.242194\n",
       "1   0.216455\n",
       "2   0.561687\n",
       "3  -0.307243\n",
       "4  -0.779873\n",
       "..       ...\n",
       "95 -1.415000\n",
       "96 -0.014525\n",
       "97  1.747559\n",
       "98 -1.560561\n",
       "99  1.099646\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"values\": np.random.randn(100)})\n",
    "min = df[\"values\"].min()\n",
    "max = df[\"values\"].max()\n",
    "df[\"values\"] = [(x-min)/(max-min) for x in df[\"values\"]]\n",
    "print(\"min-max normalization:\")\n",
    "display(df)\n",
    "\n",
    "df = pd.DataFrame({\"values\": np.random.randn(100)})\n",
    "mean = df[\"values\"].mean()\n",
    "std = df[\"values\"].std()\n",
    "df[\"values\"] = df[\"values\"].apply(lambda x: (x-mean)/std)\n",
    "print(\"z-normalization:\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Encoding features: dimensinality reduction\n",
    "1. Feature selection\n",
    "1.1 Filtering approaches\n",
    "ranking the input features based on the correlation with the output (target) feature, using information gain\n",
    "1.2 Wrapper approaches\n",
    "iteratively choosing features based on their effect/presence in models generated by a specific learning algorithms\n",
    "\n",
    "2. Principal Component Analysis(PCA)\n",
    "projecting multiple numerical features into new features by a **linear combination**, ordered by the amount of variability they can account for, from which the (k) highest ranked are chosen. (O(p^2n+n^3))\n",
    "\n",
    "3. Random Projection (RP)\n",
    "projecting multiple numerical features into (k) new features using a sparse random matrix; computationally not so costly.\n",
    "(O(pnk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exams:\n",
    "  \n",
    "1 Will mean-value imputation have the same effect, if performed\n",
    "before normalization, on the distribution of the normalized\n",
    "values for those values that were originally not missing, for\n",
    "min-max normalization and z-normalization? Explain your\n",
    "reasoning.  \n",
    "\n",
    "2 Will the use of min-max normalization prior to the use of\n",
    "equal-sized binning have any effect on model building\n",
    "compared to just using equal-sized binning (without\n",
    "normalization)? Explain your reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   values\n",
       "0     2.0\n",
       "1     2.0\n",
       "2     2.0\n",
       "3     NaN\n",
       "4     5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-value imputation + minmax normalization:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   values\n",
       "0    0.00\n",
       "1    0.00\n",
       "2    0.00\n",
       "3    0.25\n",
       "4    1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax normalization + mean-value imputation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   values\n",
       "0    0.00\n",
       "1    0.00\n",
       "2    0.00\n",
       "3    0.25\n",
       "4    1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-value imputation + z-normalization:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.732051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     values\n",
       "0 -0.577350\n",
       "1 -0.577350\n",
       "2 -0.577350\n",
       "3  0.000000\n",
       "4  1.732051"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-normalization + mean-value imputation :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   values\n",
       "0    -0.5\n",
       "1    -0.5\n",
       "2    -0.5\n",
       "3     0.0\n",
       "4     1.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 1\n",
    "# Will mean-value imputation have the same effect, if performed before normalization,\n",
    "# on the distribution of the normalized values for those values that were originally not missing, \n",
    "# for min-max normalization and z-normalization? Explain your reasoning.\n",
    "print(\"original dataframe\")\n",
    "df = pd.DataFrame({\"values\":[2,2,2,np.nan,5]})\n",
    "display(df)\n",
    "print(\"mean-value imputation + minmax normalization:\")\n",
    "df = pd.DataFrame({\"values\":[2,2,2,np.nan,5]})\n",
    "# firstly mean value imputation\n",
    "df[\"values\"].fillna(df[\"values\"].mean(), inplace=True)\n",
    "# and then minmax normalization\n",
    "df[\"values\"] = df[\"values\"].apply(lambda x: (x-df[\"values\"].min())/(df[\"values\"].max()-df[\"values\"].min()))\n",
    "display(df)\n",
    "\n",
    "print(\"minmax normalization + mean-value imputation:\")\n",
    "df = pd.DataFrame({\"values\":[2,2,2,np.nan,5]})\n",
    "# firstly mean value imputation\n",
    "df[\"values\"].fillna(df[\"values\"].mean(), inplace=True)\n",
    "# and then minmax normalization\n",
    "df[\"values\"] = df[\"values\"].apply(lambda x: (x-df[\"values\"].min())/(df[\"values\"].max()-df[\"values\"].min()))\n",
    "display(df)\n",
    "\n",
    "print(\"mean-value imputation + z-normalization:\")\n",
    "df = pd.DataFrame({\"values\":[2,2,2,np.nan,5]})\n",
    "# firstly mean value imputation\n",
    "df[\"values\"].fillna(df[\"values\"].mean(), inplace=True)\n",
    "# and then z normalization\n",
    "df[\"values\"] = df[\"values\"].apply(lambda x: (x-df[\"values\"].mean())/df[\"values\"].std())\n",
    "display(df)\n",
    "\n",
    "print(\"z-normalization + mean-value imputation :\")\n",
    "df = pd.DataFrame({\"values\":[2,2,2,np.nan,5]})\n",
    "# firstly z normalization\n",
    "df[\"values\"] = df[\"values\"].apply(lambda x: (x-df[\"values\"].mean())/df[\"values\"].std())\n",
    "# and then mean value imputation\n",
    "df[\"values\"].fillna(df[\"values\"].mean(), inplace=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:  \n",
    "As tested above, mean value imputation can be applied before or after min-max normalization and there is no difference \n",
    "However, mean value imputation applied before or after z-normalization is different and a as shown in the test, firstly apply imputation will cause a wider span of values.\n",
    "\n",
    "That of course is due to min-max is linear but z-normalization is non-linear so the sequence is important to z-transformation.\n",
    "\n",
    "Actually,  \n",
    "The estimated standard deviation is used as a denominator when z-normalization is applied, and since this will be reduced due to that missing values will be replaced by the mean, it means that values that are different from the mean will end up more far away from the mean after missing values have been imputed. As the minimum and maximum values are not affected by mean-value imputation, min-max normalization will result in the same values as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply min-max normalization before discretization (equal-sized binning):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  values\n",
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      2\n",
       "4      2\n",
       "5      3\n",
       "6      4\n",
       "7      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply equal-sized binning only:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  values\n",
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      2\n",
       "4      2\n",
       "5      3\n",
       "6      4\n",
       "7      4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# question 2\n",
    "# Will the use of min-max normalization prior to the use of equal-sized binning have \n",
    "# any effect on model building compared to just using equal-sized binning (without normalization)? \n",
    "# Explain your reasoning.\n",
    "\n",
    "print(\"apply min-max normalization before discretization (equal-sized binning):\")\n",
    "df = pd.DataFrame({\"values\":[0,1,2,3,4,5,99,100]})\n",
    "# apply min-max normalization before discretization (equal-sized binning)\n",
    "df[\"values\"] = df[\"values\"].apply(lambda x: (x-df[\"values\"].min())/(df[\"values\"].max()-df[\"values\"].min()))\n",
    "res, bins = pd.qcut(df[\"values\"], 5, retbins=True, labels=False)\n",
    "df[\"values\"] = res.astype(\"category\")\n",
    "display(df)\n",
    "\n",
    "print(\"apply equal-sized binning only:\")\n",
    "# only apply binning\n",
    "df = pd.DataFrame({\"values\":[0,1,2,3,4,5,99,100]})\n",
    "res, bins = pd.qcut(df[\"values\"], 5, retbins=True, labels=False)\n",
    "df[\"values\"] = res.astype(\"category\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "applying min-max normalization or not before discretization does not have any effect on the final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Evaluation protocols\n",
    "* Stratified split=class proportions are approximately the same\n",
    "* N-fold cross-validation (stratified cross-validation)  \n",
    "\n",
    "class sklearn.model_selection.StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)\n",
    "\n",
    "* Predicted class  \n",
    "prediction +- decides positive or negative  \n",
    "prediction==real decides true or false\n",
    "\n",
    "|     |(predict)+    |(predict)- |\n",
    "| --- | --- | --- |\n",
    "|(real)+|True positive |false negative|\n",
    "|(real)-|false positive|true negative |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Performance metrics for classification\n",
    "* Accuracy: fraction of correct predictions  \n",
    "Accuracy = (tp + tn)/(tp+fp+tn+fn)\n",
    "\n",
    "`memorize it with tp`\n",
    "\n",
    "* Precision: fraction of correct predictions for a class  \n",
    "Precision = tp/(tp+fp)\n",
    "\n",
    "for judge someone has commited a crime, need a high precision fp should be low\n",
    "\n",
    "* Recall: fraction of certain class correctly predicted\n",
    "Recall = tp/(tp+fn)\n",
    "\n",
    "for Earthquake detection, need a high recall (fn should be low)\n",
    "\n",
    "`memorize it horizontally`\n",
    "\n",
    "* TP rate (same as Recall)\n",
    "TPR = tp/(tp+fn)\n",
    "\n",
    "* FP rate\n",
    "FPR = fp/(fp+tn)\n",
    "\n",
    "> select TPR and FPR as the metrics of ROC/AUC, the reason is to avoid the bad effect of inbalanced samples  \n",
    "TPR only consider the real+ coverage and FPR only consider the real- coverage and do nothing to each other  \n",
    "so however the sample are inbalanced, the ROC curve do not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pos = [1,1,1,1,0,1,0,0]\n",
    "neg = [0,0,1,0,1,0,2,1]\n",
    "tpr = [cs/sum(pos) for cs in np.cumsum(pos)]\n",
    "fpr = [cs/sum(neg) for cs in np.cumsum(neg)]\n",
    "plt.plot([0.0]+fpr+[1.0],[0.0]+tpr+[1.0],\"-\",label=\"1\")\n",
    "plt.plot([0.0,1.0],[0.0,1.0],\"--\",label=\"Baseline\")\n",
    "plt.xlabel(\"fpr\")\n",
    "plt.ylabel(\"tpr\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C']\n",
      "[1] [0, 2, 3, 4]\n",
      "[0, 2, 3] [1, 4]\n",
      "[4] [0, 1, 2, 3]\n",
      "[0.2, 0.6, 0.2]\n",
      "[0.75, 0.8333333333333334, 1.0]\n",
      "AUC: 0.8500000000000001\n"
     ]
    }
   ],
   "source": [
    "def auc(df,correctlabels):\n",
    "    new_df=df.copy()\n",
    "    lens=len(correctlabels)\n",
    "    cols=new_df.columns.tolist()\n",
    "    print(cols)\n",
    "    if len(cols)<3: #binary ;only Pos and Neg\n",
    "        pos=[i for i in range(lens)  if correctlabels[i]==cols[0]]\n",
    "        neg=[i for i in range(lens)  if correctlabels[i]!=cols[0]]                    \n",
    "        print(pos,neg)\n",
    "        one=new_df[cols[0]]\n",
    "        auc = 0\n",
    "        for i in pos:\n",
    "            for j in neg:\n",
    "                if one[i] > one[j]:\n",
    "                    auc += 1\n",
    "                elif one[i] == one[j]:\n",
    "                    auc += 0.5\n",
    "\n",
    "        return auc / (len(pos)*len(neg))\n",
    "    else:      # CLASS >=3   Pos / non-Pos\n",
    "        aucs=[]\n",
    "        for col in cols:\n",
    "            pos=[i for i in range(lens)  if correctlabels[i]==col]\n",
    "            nonpos=[i for i in range(lens)  if correctlabels[i]!=col]                      \n",
    "            print(pos,nonpos)\n",
    "            one=new_df[col]\n",
    "            auc = 0\n",
    "            for i in pos:\n",
    "                for j in nonpos:\n",
    "                    if one[i] > one[j]:\n",
    "                        auc += 1\n",
    "                    elif one[i] == one[j]:\n",
    "                        auc += 0.5\n",
    "            auc=auc/(len(pos)*len(nonpos))\n",
    "            aucs.append(auc)\n",
    "        weights=[correctlabels.count(col)/len(correctlabels) for col in cols ]\n",
    "        print(weights)\n",
    "        print(aucs)\n",
    "\n",
    "        weights=np.array(weights)\n",
    "        aucs=np.array(aucs)\n",
    "        avg_auc=np.sum(aucs*weights)\n",
    "        return avg_auc\n",
    "\n",
    "# test\n",
    "predictions = pd.DataFrame({\"A\":[0.5,0.5,0.5,0.25,0.25],\"B\":[0.5,0.25,0.25,0.5,0.25],\"C\":[0.0,0.25,0.25,0.25,0.5]})\n",
    "\n",
    "correctlabels = [\"B\",\"A\",\"B\",\"B\",\"C\"]\n",
    "\n",
    "print(\"AUC: {}\".format(auc(predictions,correctlabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Brier score(quadratic loss): also known as mean squared error(MSE)\n",
    "\\begin{equation}\n",
    "Brier score=\\frac{1}{n}\\sum_{i=1}^n (p_i-o_i)^2\n",
    "\\end{equation}\n",
    "where $p_i$ are the predicted and $o_i$ the actual(observed) **probabilities** for test instance i, where usually all values are 0 except 1 of the true class label)\n",
    "\n",
    "\n",
    "### 3.8 Performance metrics for regression\n",
    "\n",
    "where $p_i$ is the predicted and $o_i$ the actual (observed) target\n",
    "**(regression) value** for test instance i\n",
    "* MSE  \n",
    "\\begin{equation}\n",
    "MSE=\\frac{1}{n}\\sum_{i=1}^n (p_i-o_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "* Log loss\n",
    "\\begin{equation}\n",
    "Log loss=\\frac{1}{n}\\sum_{i=1}^n o_i log p_i\n",
    "\\end{equation}\n",
    "\n",
    "* RMSE  \n",
    "square root of MSE\n",
    "\n",
    "* Mean Absolute Error (MAE)  \n",
    "\\begin{equation}\n",
    "MAE=\\frac{1}{n}\\sum_{i=1}^n |p_i-o_i|\n",
    "\\end{equation}\n",
    "\n",
    "* Pearson correlation coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exam Questions  \n",
    "1.\n",
    "Assume that we have two classification models M1 and M2\n",
    "that are evaluated on five test instances. Show with an\n",
    "example that M1 can have a higher accuracy than M2, while\n",
    "at the same time M2 has a higher area under the ROC curve\n",
    "(AUC) than M1.\n",
    "\n",
    "Answer:\n",
    "```\n",
    "y_real = [1,0,0,0,0]\n",
    "\n",
    "M1_pred = [0,0,0,0,0]\n",
    "M2_pred = [1,0,0,1,1]\n",
    "```\n",
    "In this case, we can get the confusion matrix as following:\n",
    "\n",
    "||pos|neg|\n",
    "| --- | --- | --- |\n",
    "|M1|||\n",
    "|true|0|1|\n",
    "|false|0|4|\n",
    "|M2|||\n",
    "|true|1|0|\n",
    "|false|2|2|\n",
    "\n",
    "and calculate the accuracy, where M1 is 0.8 and M2 is 0.6. Simutaneously, for the AUC, M1 is 0 and M2 is 0.75.  \n",
    "\n",
    "> The area under the ROC curve (AUC) = the probability of an example belonging to the class being ranked ahead of an example not belonging to the class\n",
    "so for M2, when there is one p(positive) and 4 n(negative) real cases, we predict p1:1.0, n1:1.0, n2:1.0, n3:0.0, n4:0.0. AUC = (0.5+0.5+1.0+1.0)/(1*4)=0.75\n",
    "\n",
    "\n",
    "2.\n",
    "Assume that we have generated a regression model for predicting the outdoor temperature using a large training set. However, we then find out that the MSE of the model is significantly higher than of a default model, which just predicts the average outdoor temperature in the training set. Could our model still be more useful for prediction tasks than the default model?\n",
    "\n",
    "Answer:\n",
    "\n",
    "If we would be interested in finding out which dats are expected to be the warmest, e.g., when planning some outdoor activities, then we are more interested in the correlation between the predicted and actual temperatures, rather than being interested primarily in the absolute temperatures. The trained model with a poorer MSE may hence be more useful for this purpose than the default model, it the correlation coefficient of the former is positive(while this is not the case for the default model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Linear Models\n",
    "\n",
    "use linear models when:  \n",
    "* Small number of training data\n",
    "* Low signal-to-noise  \n",
    "* Sparse data  \n",
    "\n",
    "The model of choice is in for of $y=w_0+\\sum_{j=1}^m x_j w_j + \\epsilon$\n",
    "\n",
    "where input vector is $x=(x_1,...,x_m)$  \n",
    "output is y  \n",
    "and weight is $w_j$ also known as regressor that are unknown \n",
    "$\\epsilon$ is the unobserved error term that has the mean of zero: $\\epsilon ~ N(0, \\sigma^2)$\n",
    "\n",
    "The goal is to find such w to make the value of cost function(MSE or RSS) as low as possible.\n",
    "\n",
    "To minimize the RSS: \n",
    "\n",
    "\n",
    "$RSS_{min} = min_w (Y-XW)^T(Y-XW)$\n",
    "\n",
    "We can prove the weight to achieve the minimal RSS is:\n",
    "\n",
    "$W = (X^TX)^{-1}X^Ty$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.35278074],\n",
       "       [2.73088907]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[4.35278074],\n",
       "       [9.81455889]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# linear regression\n",
    "import numpy as np\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# use the above formula to calculate W, estimate to find the approximate bias 4, weight 3\n",
    "# add bias x0=1 to each instance, which is the bias (x0 can be an arbitrary number but not 0)\n",
    "# https://www.quora.com/Why-add-extra-ones-as-first-column-of-data-in-machine-learning\n",
    "# np.c_ is to concat two arrays by row\n",
    "# np.r_ is to concat two arrays by column\n",
    "X_b = np.c_[np.ones((100,1)), X]\n",
    "# linear algebra module\n",
    "w_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "# display the two weights corrsponding to bias 1 and X\n",
    "display(w_best)\n",
    "\n",
    "# predict using the w_best\n",
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2,1)), X_new] # add the bias 1 to each intance\n",
    "y_predict = X_new_b.dot(w_best)\n",
    "display(y_predict)  # 4+3*X + 1 estimated to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aboved method, which directly compute the most appropriate parameters of the model, is a so-called close form method. \n",
    "\n",
    "However, the time complexity is between $O(n^{2.4})$ to $O(n^3)$ due to the inverse computation, which is very high.\n",
    "\n",
    "So we should introduce **Gradient Descent**.\n",
    "\n",
    "repeating updating weights until the output is close enough to the estimated output\n",
    "\n",
    "$ w_i := w_i - \\frac{t}{m}\\sum_{i=1}^m(y-y_i)^2*x_0$\n",
    "\n",
    "We should also examine the **Logistic Regression**, which use the `binary cross entropy` as the cost function and yield the categorical output.\n",
    "\n",
    "$h_w(X) = g(W^TX)$\n",
    "\n",
    "$g(z)=\\frac{1}{e^{-z}+1}$\n",
    "\n",
    "if $g(z)>=0.5$  Y=1, else  Y=0\n",
    "\n",
    "The lost function is \n",
    "\n",
    "$J(w) = -\\frac{1}{m}\\sum_i^my_ilog(h_w(x_i)) + (1-y_i)log(1-h_w(x_i))$\n",
    "\n",
    "Inference:\n",
    "\n",
    "When $W^TX<0$, the predicted label is $Y=0$\n",
    "\n",
    "When $W^TX>0$, the predicted label is $Y=1$\n",
    "\n",
    "* The reason that it do not use MAE but binary cross entropy is that the derivative of sigmoid will be zero.\n",
    "\n",
    "* Unlike the case of linear regression, minimizing cross entropy cannot lead to a closed form solution because of the unlinearity of the sigmoid. \n",
    "\n",
    "\n",
    "Regularization is a technique one uses to \n",
    "* prevent overfitting (the model cannot generalize well to the test/unseen data)\n",
    "* when learning is ill-posed (when there are more features than instances)\n",
    "\n",
    "L1 regularization (Lasso)  \n",
    "$\\sum_1^n(y-y_i)^2 + \\lambda\\sum_1^n|w_i|$\n",
    "\n",
    "L2 regularization\n",
    "$\\sum_1^n(y-y_i)^2 + \\lambda\\sum_1^nw_i^2$\n",
    "\n",
    "Elastic net\n",
    "\n",
    "$\\sum_1^n(y-y_i)^2 + \\lambda\\sum_1^n|w_i| + \\lambda\\sum_1^nw_i^2$\n",
    "\n",
    "> the rationale for choosing polynomial is that it is almost impossible to show the feature of regularization in 2 dimensions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Naive Bayes and KNN\n",
    "\n",
    "### 5.1 Naive Bayes theorem\n",
    "\n",
    "two equations:\n",
    "1. \n",
    "$P(H|E) = \\frac{P(H)P(E|H)}{P(E)}$\n",
    "2.\n",
    "$P(x_1 \\& x_2 \\&... \\&x_m|c) = P(x_1|c)P(x_2|c)...P(x_m|c)$\n",
    "\n",
    "\n",
    "If we want to get the probability of a result (e.g. r, can be + or -) when several conditions (e.g. c) happen, we can write following equation:\n",
    "\n",
    "$P(r_+|c1 \\& c2 \\& c3)$\n",
    "\n",
    "However, we cannot compute the probability directly with this equation\n",
    "\n",
    "So we use the first equation\n",
    "\n",
    "$P(r_+|c1 \\& c2 \\& c3) = \\frac{P(r_+)P(c1 \\& c2 \\& c3|r_+)}{P(c1 \\& c2 \\& c3)}$\n",
    "\n",
    "$P(r_+|c1 \\& c2 \\& c3) = \\frac{P(r_+)P(c1 \\& c2 \\& c3| r_+)}{P(c1 \\& c2 \\& c3, r_+) + P(c1 \\& c2 \\& c3, r_-)}$\n",
    "\n",
    "$P(r_+|c1 \\& c2 \\& c3) = \\frac{P(r_+)P(c1 \\& c2 \\& c3| r_+)}{P(r_+)P(c1 \\& c2 \\& c3| r+) + P(r_-)P(c1 \\& c2 \\& c3| r-)}$\n",
    "\n",
    "\n",
    "use the second equation\n",
    "\n",
    "$P(r_+|c1 \\& c2 \\&c3) = \\frac{P(r_+)P(c1|r_+)P(c2|r_+)P(c3|r_+)}{P(r_+)P(c1|r_+)P(c2|r_+)P(c3|r_+) + P(r_-)P(c1|r_-)P(c2|r_-)P(c3|r_-)}$\n",
    "\n",
    "where each term can be easily obtained from the original dataframe\n",
    "\n",
    "* What if some condition there is no records?  \n",
    "To prevent from dividing by zero, sometimes we should use **Laplace correction**, which add each condition by 1 to ensure that no 0 would be in the denominator.\n",
    "\n",
    "* What if some feature value is missing (np.nan) for an instance  \n",
    "For a test instance: ignore the feature when calculating class probabilities  \n",
    "For a training instance: ignore the feature when updating counts\n",
    "\n",
    "* What if some feature is numerical?  \n",
    "Employ discretization(binning)  \n",
    "Use a probability density function (assume normal distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Other</th>\n",
       "      <th>Bar</th>\n",
       "      <th>Fri/Sat</th>\n",
       "      <th>Hungry</th>\n",
       "      <th>Guests</th>\n",
       "      <th>Wait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>some</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>full</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e3</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>some</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>full</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e5</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e6</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>some</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Other  Bar Fri/Sat Hungry Guests Wait\n",
       "0  e1   yes   no      no    yes   some  yes\n",
       "1  e2   yes   no      no    yes   full   no\n",
       "2  e3    no  yes      no     no   some  yes\n",
       "3  e4   yes   no     yes    yes   full  yes\n",
       "4  e5   yes   no     yes     no   none   no\n",
       "5  e6    no  yes      no    yes   some  yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.DataFrame({\"ID\":[\"e1\",\"e2\",\"e3\",\"e4\",\"e5\",\"e6\"],\n",
    "                        \"Other\":[\"yes\",\"yes\",\"no\",\"yes\",\"yes\",\"no\"], \n",
    "                         \"Bar\":[\"no\",\"no\",\"yes\",\"no\",\"no\",\"yes\"],\n",
    "                         \"Fri/Sat\":[\"no\",\"no\",\"no\",\"yes\",\"yes\",\"no\"],\n",
    "                        \"Hungry\":[\"yes\",\"yes\",\"no\",\"yes\",\"no\", \"yes\"],\n",
    "                        \"Guests\":[\"some\",\"full\",\"some\",\"full\",\"none\",\"some\"],\n",
    "                        \"Wait\":[\"yes\",\"no\",\"yes\",\"yes\",\"no\",\"yes\"]})\n",
    "display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yes': 4, 'no': 2}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{('no', 'no'): 2, ('no', 'yes'): 0, ('yes', 'no'): 2, ('yes', 'yes'): 2}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = dataframe.copy()\n",
    "df[\"Wait\"] = df[\"Wait\"].astype(\"category\")\n",
    "display(df[\"Wait\"].value_counts().to_dict())\n",
    "display(df.groupby([\"Wait\",\"Bar\"]).size().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a simple NaiveBayes\n",
    "# omit possible steps of imputation, discretization and column filter\n",
    "def fit(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    feature_class_counts = {}\n",
    "    # a mapping from a col to a dictionary((c,v),num of this combination)\n",
    "    feature_class_value_counts = {}\n",
    "    \n",
    "    df[\"Wait\"] = df[\"Wait\"].astype(\"category\")\n",
    "    \n",
    "    feature_class_counts = df[\"Wait\"].value_counts().to_dict()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col not in [\"Wait\", \"ID\"]:\n",
    "            feature_class_value_counts[col] = df.groupby([\"Wait\",col]).size().to_dict()\n",
    "    \n",
    "    return feature_class_value_counts, feature_class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of 'wait' to be yes, when hungry is yes, Guests is full and bar is no:\n",
      "0.4285714285714286\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "# want to know the probability of \"wait\" to be \"yes\" when \n",
    "# following conditions are true\n",
    "# \"hungry\" : \"yes\"\n",
    "# \"Guests\" : \"full\"\n",
    "# \"Bar\" : \"no\"\n",
    "feature_class_value_counts, feature_class_counts = fit(df)\n",
    "prediction_df = pd.DataFrame({\"Wait\":['yes'],\n",
    "                              \"Hungry\":[\"yes\"], \n",
    "                              \"Guests\":[\"full\"],\n",
    "                             \"Bar\":[\"no\"]})\n",
    "# display(prediction_df)\n",
    "\n",
    "# display(feature_class_counts)\n",
    "wait_class = prediction_df[\"Wait\"][0] # wait yes\n",
    "\n",
    "\n",
    "\n",
    "prob_wait_class = feature_class_counts[wait_class] / sum(feature_class_counts.values())\n",
    "\n",
    "prob_nominator = prob_wait_class\n",
    "\n",
    "prediction_df.drop(columns=\"Wait\", inplace=True)\n",
    "for i in prediction_df.columns:\n",
    "    prob_nominator *= feature_class_value_counts[i][(wait_class, prediction_df[i][0])] / feature_class_counts[wait_class]\n",
    "\n",
    "# display(feature_class_value_counts)\n",
    "\n",
    "prob_denominator = 0\n",
    "\n",
    "for c in feature_class_counts.keys():  # yes, no\n",
    "    prob_denominator_class = feature_class_counts[c] / sum(feature_class_counts.values())\n",
    "    for i in prediction_df.columns:  # \"Hungry\"...\n",
    "        prob_denominator_class *= feature_class_value_counts[i][(c,prediction_df[i][0])] / feature_class_counts[c]\n",
    "        \n",
    "    prob_denominator += prob_denominator_class\n",
    "\n",
    "print(\"probability of 'wait' to be yes, when hungry is yes, Guests is full and bar is no:\")\n",
    "prob_res = prob_nominator / prob_denominator\n",
    "print(prob_res)                                      \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 KNN\n",
    "\n",
    "Input: test instance e, training examples E, constant k  \n",
    "Output: class label c  \n",
    "\n",
    "Let N be the k closest instances to e in E  \n",
    "Let c be the majority class of N\n",
    "\n",
    "To calculate the distance  \n",
    "* categorical features are converted to numerical  \n",
    "* missing values are imputed\n",
    "* numerical features are **normalized**\n",
    "\n",
    "In practice  \n",
    "* size grows with the number of training instances, which may prevent the algorithm from being used in resource-constrained environments\n",
    "* The computational bottleneck is during predictions, as each test instance requires distance calculation for all trainining instances\n",
    "* speed up (reduce dimensionality; sample training data or prototype selection; partitioning the feature space e.g. by k-d trees)\n",
    "\n",
    "\n",
    "```python\n",
    "def euclidean_distance(row1, row2):\n",
    "    return np.sqrt(np.sum(np.power(row1 - row2, 2), axis=0))\n",
    "```\n",
    "\n",
    "During training of KNN, we just need to preprocess the dataset (one-hot to numerical, imputation and normalize). When predicting, we should calculate the euclidean distance of the test row to all the training row. Then we sort the distance and find the K rows with the least distance and then, let the majority class be the class of the test row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Artificial Neural Networks\n",
    "\n",
    "When the number of dimensions grow, the number of cells(regions) grows exponentially, so we would need a large quantity of training data to ensure that those cells are not empty. It may be impossible to get such data but still feasible to make sense because\n",
    "\n",
    "* The real data is usually confined to a region of space with low effective dimensions\n",
    "* Real data in high dimension shows smoothness, at least locally and small changes in the input variable will still produce small changes in the target variables\n",
    "\n",
    "Neural networks: Input layer, hidden layer, output layer  \n",
    "Without a hidden layer, it's a logistic regression\n",
    "\n",
    "In the hidden layer, we have  \n",
    "$y=g(w^Tx+w_0)$  \n",
    "and g(.) is called an **activation function** and has `Non-linearity`, `Monotonicity` and `Differentiability`. e.g. Sigmoid, ReLu, Tanh\n",
    "\n",
    "In numpy implementation, Decision boundary will become more thick when learning rate goes down.\n",
    "\n",
    "Possible regularization techniques\n",
    "* L1/L2 regularization\n",
    "* Dropout\n",
    "* Early stopping\n",
    "\n",
    "The implementation by numpy\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def loss(y_hat, y):\n",
    "    return np.mean(np.abs(y_hat - y))\n",
    "\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "def d_sigmoid(output):\n",
    "    return output*(1-output)\n",
    "\n",
    "\n",
    "def forward_propagation(a_0, w_0, w_1, dropout_rate=0):\n",
    "    z_1 = np.matmul(a_0, w_0)\n",
    "    a_1 = sigmoid(z_1)\n",
    "\n",
    "    if dropout_rate != 0:\n",
    "        a_1 *= np.random.binomial([np.ones((a_0.shape[0], w_0.shape[1]))], 1-dropout_rate)[0] * (1.0/(1-dropout_rate))\n",
    "\n",
    "    z_2 = np.matmul(a_1,w_1)\n",
    "    a_2 = sigmoid(z_2)\n",
    "\n",
    "    return a_1, a_2\n",
    "\n",
    "def back_propagation(w_1, a_1, a_2, y):\n",
    "    a_2_error = a_2 - y\n",
    "    layer_2_delta = np.multiply(a_2_error, d_sigmoid(a_2))\n",
    "\n",
    "    layer_1_error = np.matmul(layer_2_delta, w_1.T)\n",
    "    layer_1_delta = np.multiply(layer_1_error, d_sigmoid(a_1))\n",
    "\n",
    "    return layer_1_delta, layer_2_delta\n",
    "\n",
    "\n",
    "def train(x, y, hidden_size, alpha=1, num_iter = 60000, dropout_rate=0):\n",
    "    w_0 = 2 * np.random.random((x.shape[1], hidden_size)) - 1\n",
    "    w_1 = 2 * np.random.random((hidden_size, 1)) - 1\n",
    "    \n",
    "    loss_values = []\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        a_0 = x\n",
    "        a_1, a_2 = forward_propagation(a_0, w_0, w_1, dropout_rate)\n",
    "    \n",
    "        layer_1_delta, layer_2_delta = back_propagation(w_1, a_1, a_2, y)\n",
    "\n",
    "        w_1 -= alpha * np.matmul(a_1.T, layer_2_delta)\n",
    "        w_0 -= alpha * np.matmul(a_0.T, layer_1_delta)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            loss_values.append(loss(a_2, y))\n",
    "        \n",
    "    return {'loss': loss_values, 'w_0': w_0, 'w_1': w_1}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Decision Trees and Rules\n",
    "\n",
    "### 7.1 Introduction\n",
    "\n",
    "Input: instances I = {(X_1, y_1), ..., (X_n, y_n)}, features F  \n",
    "Output: a decision tree T\n",
    "\n",
    "The **termination condition** checks whether the instances at a current node should not be further split if:\n",
    "- all instances share the same label(**pure** node)\n",
    "- the number of instances are less than a specifies threshold, e.g., **min_samples_split**\n",
    "- the node is at a certain depth in the tree, e.g., **max_depth**\n",
    "\n",
    "A leaf node is inserted in the decision tree, whenever the termination condition is satisfied. The leaf node is created using the local instances and may be **labeled with**:\n",
    "- in the case of classification, either the most frequent class label (resulting in classification trees) or a class probability\n",
    "- in the case of regression, the mean of the target values of the local instances\n",
    "- in the case that the set of local instances is empty, a label formed from the information in the **parent node**\n",
    "\n",
    "\n",
    "For feature which only has binary values(feature, non-feature), we have a **deeper** tree. For feature which have multiple possible categorical value, we have a **wider** tree.\n",
    "\n",
    "For feature which is numerical, we set a threshold value.\n",
    "\n",
    "### 7.2 Interpretability\n",
    "\n",
    "Measure the impurity by entropy(information gain)\n",
    "\n",
    "$E(P(e_1),...P(e_k)) = - \\sum_1^kP(e_i)log_2(P(e_i))$\n",
    "\n",
    "Impurity (See pdf)\n",
    "\n",
    "### 7.3 The replication problem\n",
    "\n",
    "For decision tree, we may rediscover replicated rules, which means we have a lot of leafs that express the same thing. So we need rule learning, which will **remove the instances that covered by the rule** so we do not need to rethink the same decision in the rule and we start from a **fresh(new) rule** to narrow down the instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Combining Models\n",
    "\n",
    "### 8.1 Condorcet's theorem\n",
    "For every person he/she have a probability p to make the correct vote. If p>0.5, then with more people voting, the more likely it will be correct for the group vote result.\n",
    "\n",
    "\n",
    "### 8.2 Bagging\n",
    "**Bootstrap** sampling: randomly selecting one instance n times(n=|I|) from I instances (select randomly one instance for each time and put it back).\n",
    "\n",
    "A subset of instances (n=|I|) is extracted from Bootstrap sampling.\n",
    "\n",
    "The set of other instances that has not been extracted is the out-of-bag set.\n",
    "\n",
    "Input: instances I, Learner L, iterations m\n",
    "Output: a combined model M\n",
    "\n",
    "```python\n",
    "for i=1 to m:\n",
    "    B = bootstrap sample of I\n",
    "    M_i = L(B)\n",
    "M = average({M_1, ..., M_m}) \n",
    "# classification: average is majority vote; regression: mean of the predicted values\n",
    "```\n",
    "\n",
    "* For decision trees, pruning often has a detrimental effect, i.e., the more variance of each individual model the better\n",
    "\n",
    "* Predictive performance can be measured without a seperate validation/test set (out-of-bag samples)\n",
    "\n",
    "\n",
    "### 8.3 Random forest\n",
    "\n",
    "* bagging\n",
    "* the random subspace method: consider only a random sample of the features; either one sample for each tree or one sample for each split (based on the entropy or gini index, used for RF).\n",
    "\n",
    "multiple bootstraping decision trees compose the random forest\n",
    "\n",
    "### 8.4 Boosting\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/43443518\n",
    "\n",
    "Train set remains the same (no bootstraping), just the weights of the samples are changing. They are increasing if they yield small error (err=0) when the overall error (Err) is big. In contrast, they are decreasing to zero because they has already yied a good Err and not need to be tuned.\n",
    "\n",
    "```python\n",
    "# AdaBoost\n",
    "# Input: instances {Z_1,...Z_n}\n",
    "# Output: a set of model-weight pairs M\n",
    "w1, ..., w_n = 1\n",
    "M = {}\n",
    "for i = 1 to m:\n",
    "    M_i = L({(Z_1, w_1), ... (Z_n, w_n)})\n",
    "    Err = (w_1*err(M_i,z_1)+...+w_m*err(M_i,z_n))/\n",
    "    (w_1+...+w_n) # overall Err\n",
    "    if Err = 0 or Err > 0.5 then break # good enough or too bad\n",
    "    for j = 1 to m:\n",
    "        if err(M_i, Z_j) = 0 then w_j = w_j * Err/(1-Err) # bad features add weights, good features decrease weights for the next round\n",
    "    M = M + {(M_i, -log Err/(1-Err))} # Model-weight pair\n",
    "\n",
    "```\n",
    "\n",
    "not understand\n",
    "```python\n",
    "# Gradient boosting\n",
    "# Input: instances {(X_1,y_1), ..., (X_n,y_n)}, learner L, iterations m\n",
    "# Output: a sequence of model M_0, ... M_m\n",
    "\n",
    "M_0 = (y_1 + ... + y_n) / n\n",
    "for i=1 to m:\n",
    "    for j=1 to n:\n",
    "        y_j = y_j - M_i-1 (X_j)  # until residue y_j equals zero\n",
    "        M_i = L({(X_1,y_1), ..., (X_n,y_n)})\n",
    "\n",
    "```\n",
    "\n",
    "### 8.5 Stacking\n",
    "\n",
    "* Linear models have been shown to be effective when learning the combination function\n",
    "\n",
    "* Predictive performance can be improved by combining class probability estimates rather than class labels generated by the base models \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Practical Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Unsupervised Learning\n",
    "\n",
    "### 11.1 The k-means algorithm\n",
    "\n",
    "```python\n",
    "Input: instances X={X1, ... , Xn}, number of clusters k\n",
    "Output: a set of clusters {C1, ..., Ck}\n",
    "\n",
    "{C1, ..., Ck} = a randomized partitioning of X\n",
    "\n",
    "repeat\n",
    "    c1, ... ck = centroids of C1, ..., Ck\n",
    "    \n",
    "    move each instance Xi to the cluster Cj,\n",
    "    which corresponds to the closest centroid cj\n",
    "\n",
    "until no intance was moved to another cluster\n",
    "```\n",
    "\n",
    "* Distance metrics  \n",
    "Euclidean distance, Manhattan distance, Hamming distance\n",
    "\n",
    "* Sum-of-squared-error\n",
    "$SSE(C) = \\sum\\sum(o-cent_j)^2$\n",
    "\n",
    "* Sihouette value\n",
    "$s(o) = \\frac{b(o)-a(o)}{max\\{a(o),b(o)\\}}$  \n",
    "where a(o) is the average distance to objects in the cluster of o and b(o) is the average distance to objects in the nearest cluster not including o  \n",
    "\n",
    "The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters.\n",
    "\n",
    "### 11.2 Bottom-up(agglomerative) clustering\n",
    "\n",
    "```python\n",
    "Input: instances X1, ..., Xn\n",
    "Output: a binary hierarchical cluster H\n",
    "\n",
    "H = {{X1}, ..., {Xn}}\n",
    "\n",
    "for i =1 to n-1:\n",
    "    select two elements H1 and H2 in H\n",
    "    H = H \\ {H1, H2} Union {{H1, H2}}\n",
    "```\n",
    "\n",
    "select the two nearest cluster H1 and H2 to merge based on:\n",
    "- Complete-linkage\n",
    "- Single-linkage\n",
    "- Average-linkage\n",
    "- Ward's variance criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[6, 7, 9], [3, 4, 5]], [[0, 2], [1, 8]]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top down clustering\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def top_down_clustering(C,X,min_cluster=5):\n",
    "    if no_split(C,min_cluster):\n",
    "        return C\n",
    "    else:\n",
    "        left_C, right_C = split_cluster(C,X)\n",
    "        return [top_down_clustering(left_C,X,min_cluster), \n",
    "              top_down_clustering(right_C,X,min_cluster)]\n",
    "\n",
    "# return only if C contains less than min_cluster instances\n",
    "def no_split(C,min_cluster):\n",
    "    return (len(C) < min_cluster)\n",
    "\n",
    "# return the indexes of two clusters\n",
    "def split_cluster(C,X):\n",
    "    # filter out the X with the current cluster index \n",
    "    X = [X[i] for i in C]\n",
    "    # form the two clusters\n",
    "    kmeans = KMeans(n_clusters=2).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    # obtain the two cluster as left and right one\n",
    "    left_C = [C[i] for i,e in enumerate(labels) if e==1]\n",
    "    right_C = [C[i] for i,e in enumerate(labels) if e==0]\n",
    "    return left_C, right_C\n",
    "\n",
    "C = np.arange(10)\n",
    "X = np.random.rand(10,5)\n",
    "\n",
    "display(top_down_clustering(C,X,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
