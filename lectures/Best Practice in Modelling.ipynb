{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID2214: Programming for Data Science\n",
    "## Best Practices in Modelling\n",
    "### Amir Hossein A. Rahnama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always remember to set the seed for your experiments so that it is reproducible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to change the seed number to change the random setting to make sure\n",
    "# that your results do not coincidently work fine\n",
    "seed_number = 10\n",
    "np.random.seed(seed_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us reload and merge data as we did in the last notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb_ratings=pd.read_csv('./data/IMDb ratings.csv',usecols=['weighted_average_vote'])\n",
    "# imdb_titles=pd.read_csv('./data/IMDb movies.csv', usecols=['title','year','genre'])\n",
    "# ratings = pd.DataFrame({'Title':imdb_titles.title,\n",
    "#                     'Release Year':imdb_titles.year,\n",
    "#                     'Rating': imdb_ratings.weighted_average_vote,\n",
    "#                     'Genre':imdb_titles.genre})\n",
    "# ratings.drop_duplicates(subset=['Title','Release Year','Rating'], inplace=True)\n",
    "# ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_overall = pd.read_csv('./data/netflix_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8132b3275478>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mjoint_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetflix_overall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mjoint_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjoint_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Rating'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ratings' is not defined"
     ]
    }
   ],
   "source": [
    "ratings.dropna()\n",
    "joint_data=ratings.merge(netflix_overall, left_on='Title', right_on='title', how='inner')\n",
    "joint_data=joint_data.sort_values(by='Rating', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-38dd0f74029d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#removing stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Replace NaN with an empty string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnetflix_overall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetflix_overall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "#removing stopwords\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "netflix_overall['description'] = netflix_overall['description'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix_description = tfidf.fit_transform(netflix_overall['description'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix_description.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix_description, tfidf_matrix_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = pd.Series(netflix_overall.index, index=netflix_overall['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return netflix_overall['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_recommendations('Peaky Blinders')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_genre = CountVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "joint_data['Genre'] = joint_data['Genre'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_genre_matrix = tfidf_genre.fit_transform(joint_data['Genre'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_genre_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genre_dictionary = ['' for i in range(len(list(tfidf_genre.vocabulary_.keys())))]\n",
    "\n",
    "for gen in tfidf_genre.vocabulary_:\n",
    "    genre_dictionary[tfidf_genre.vocabulary_[gen]] = gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_director = CountVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "joint_data['director'] = joint_data['director'].replace(np.nan, '', regex=True)\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_director_matrix = tfidf_director.fit_transform(joint_data['director'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_director_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "director_dictionary = ['' for i in range(len(list(tfidf_director.vocabulary_.keys())))]\n",
    "\n",
    "for di in tfidf_director.vocabulary_:\n",
    "    director_dictionary[tfidf_director.vocabulary_[di]] = di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_country = CountVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "joint_data['country'] = joint_data['country'].replace(np.nan, '', regex=True)\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_country_matrix = tfidf_country.fit_transform(joint_data['country'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_country_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country_dictionary = ['' for i in range(len(list(tfidf_country.vocabulary_.keys())))]\n",
    "\n",
    "for co in tfidf_country.vocabulary_:\n",
    "    country_dictionary[tfidf_country.vocabulary_[co]] = co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types_data = np.argmax(pd.get_dummies(joint_data['type'], prefix='type').values, axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.hstack([tfidf_genre_matrix.toarray(), tfidf_country_matrix.toarray(), tfidf_director_matrix.toarray(), types_data])\n",
    "y = np.around(joint_data['Rating'].values).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names = np.hstack((genre_dictionary, country_dictionary, director_dictionary, ['type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = Ridge(random_state=seed_number).fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(reg.score(X_train, y_train), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "largest_weights = np.abs(reg.coef_).argsort()[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(7, 5), dpi=100)\n",
    "\n",
    "# Example data\n",
    "people = ('Tom', 'Dick', 'Harry', 'Slim', 'Jim')\n",
    "y_pos = np.arange(len(largest_weights))\n",
    "\n",
    "ax.barh(y_pos, reg.coef_[largest_weights], align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(column_names[largest_weights])\n",
    "ax.invert_yaxis()  \n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('Important Features in Ridge Regression Model')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_tree = DecisionTreeRegressor(max_depth=4, random_state= seed_number).fit(X_train, y_train)\n",
    "y_pred = d_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(reg.score(X_train, y_train), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphviz \n",
    "\n",
    "dot_data = tree.export_graphviz(d_tree, out_file=None, \n",
    "                                feature_names=column_names,  filled=True, rounded=True) \n",
    "graph = graphviz.Source(dot_data)\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_lr = {'alpha': np.linspace(0, 1, 10),\n",
    "                 'normalize': [True, False],\n",
    "                 'solver': ['auto', 'cholesky', 'sparse_cg']\n",
    "                }\n",
    "\n",
    "score = 'neg_mean_absolute_error'\n",
    "\n",
    "ridge = GridSearchCV(Ridge(random_state=seed_number), param_grid=param_lr, scoring=score)\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Best parameterse for score {}: {}'.format(s, ridge.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ridge.score(X_train, y_train), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dt = {\"max_depth\": np.arange(2, 20), \n",
    "             'splitter': ['best', 'random'],\n",
    "              'min_samples_split': np.arange(2, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = 'neg_mean_absolute_error'\n",
    "\n",
    "dt_tree_reg = GridSearchCV(DecisionTreeRegressor(random_state=seed_number), param_grid=param_dt, scoring=score)\n",
    "dt_tree_reg.fit(X_train, y_train)\n",
    "print('Best parameterse for score {}: {}'.format(s, dt_tree_reg.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_dt = dt_tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dt_tree_reg.score(X_train, y_train), mean_squared_error(y_test, y_pred_dt), mean_absolute_error(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_lr = RandomizedSearchCV(Ridge(random_state=seed_number), param_distributions=param_lr,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "random_lr.fit(X_train, y_train)\n",
    "print('Best parameterse for score {}: {}'.format(s, random_dtree.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_r_lreg = random_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(random_lr.score(X_train, y_train), mean_squared_error(y_test, y_pred_r_lreg), mean_absolute_error(y_test, y_pred_r_lreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_dtree = RandomizedSearchCV(DecisionTreeRegressor(random_state=seed_number), param_distributions=param_dt,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "random_dtree.fit(X_train, y_train)\n",
    "print('Best parameterse for score {}: {}'.format(s, random_dtree.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_dt_random = random_dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(random_dtree.score(X_train, y_train), mean_squared_error(y_test, y_pred_dt_random), mean_absolute_error(y_test, y_pred_dt_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visually compare the results of both techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_grid_score = ridge.score(X_train, y_train)\n",
    "lr_random_score = random_lr.score(X_train, y_train)\n",
    "\n",
    "lr_grid_mse =  mean_squared_error(y_test, y_pred)\n",
    "lr_random_mse = mean_squared_error(y_test, y_pred_r_lreg)\n",
    "\n",
    "lr_grid_mae = mean_absolute_error(y_test, y_pred)\n",
    "lr_random_mae = mean_absolute_error(y_test, y_pred_r_lreg)\n",
    "\n",
    "\n",
    "lr_grid_all_scores = [lr_grid_score, lr_grid_mse, lr_random_mae]\n",
    "lr_random_all_scores = [lr_random_score, lr_random_mse, lr_random_mae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_grid_score = dt_tree_reg.score(X_train, y_train)\n",
    "dt_random_score = random_dtree.score(X_train, y_train)\n",
    "\n",
    "dt_grid_mse =  mean_squared_error(y_test, y_pred_dt)\n",
    "dt_random_mse = mean_squared_error(y_test, y_pred_dt_random)\n",
    "\n",
    "dt_grid_mae = mean_absolute_error(y_test, y_pred_dt)\n",
    "dt_random_mae =  mean_absolute_error(y_test, y_pred_dt_random)\n",
    "\n",
    "dt_grid_all_scores = [dt_grid_score, dt_grid_mse, dt_grid_mae]\n",
    "dt_random_all_scores = [dt_random_score, dt_random_mse, dt_random_mae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5), dpi=100)\n",
    "\n",
    "N = 3\n",
    "width = 0.1\n",
    "\n",
    "ind = np.arange(N)\n",
    "\n",
    "ax[0].bar(ind + width, lr_grid_all_scores, width, label='Grid')\n",
    "ax[0].bar(ind - width, lr_random_all_scores, width, label='Random')\n",
    "\n",
    "ax[0].set_title('Ridge Regression')\n",
    "ax[0].set_xticks(ind + width / 2)\n",
    "ax[0].set_xticklabels(('Score', 'MSE', 'MAE'))\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].autoscale_view()\n",
    "\n",
    "\n",
    "ax[1].bar(ind + width, dt_grid_all_scores, width, label='Grid')\n",
    "ax[1].bar(ind - width, dt_random_all_scores, width, label='Random')\n",
    "\n",
    "ax[1].set_title('Decision Tree')\n",
    "ax[1].set_xticks(ind + width / 2)\n",
    "ax[1].set_xticklabels(('Score', 'MSE', 'MAE'))\n",
    "\n",
    "ax[1].legend()\n",
    "ax[1].autoscale_view()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
