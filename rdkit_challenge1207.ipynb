{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!conda install -y -c rdkit rdkit;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/samoturk/mol2vec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\nimport numpy as np\nimport pandas as pd\n\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nimport rdkit.Chem.Fragments as f\nimport rdkit.Chem.rdMolDescriptors as d\nfrom rdkit.Chem import Lipinski\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import KBinsDiscretizer\n\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\nimport xgboost as xgb\n\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom gensim.models import word2vec\nfrom mol2vec.features import mol2alt_sentence, mol2sentence, MolSentence, DfVec, sentences2vec\nfrom gensim.models import word2vec\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(path):\n    return pd.read_csv(path, index_col=[\"INDEX\"])\n\n\ndef get_smile(dataframe):\n    data = dataframe.copy()\n    data[\"rd_form\"] = data.SMILES.apply(lambda x: Chem.MolFromSmiles(x))\n    data.drop([\"SMILES\"], inplace=True, axis=1)\n    return data\n\n\n# Here test different features\ndef get_feature(dataframe):\n    data = dataframe.copy()\n    \n    mol_model = word2vec.Word2Vec.load('../input/assignment4datas/model_300dim.pkl')\n    \n    data[\"num_atom\"] = data[\"rd_form\"].apply(lambda x:x.GetNumAtoms())\n    data[\"mol_dr\"] = data[\"rd_form\"].apply(lambda x: d.CalcExactMolWt(x))\n    data[\"COO\"] = data[\"rd_form\"].apply(lambda x: f.fr_Al_COO(x))\n    data[\"OH\"] = data[\"rd_form\"].apply(lambda x: f.fr_Al_OH(x))\n    data[\"ArN\"] = data[\"rd_form\"].apply(lambda x: f.fr_ArN(x))\n    data[\"halogen\"] = data[\"rd_form\"].apply(lambda x: f.fr_halogen(x))\n    data[\"aliphatic_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAliphaticRings(x))\n    data[\"aromatic_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAromaticRings(x))\n    \n\n    # fingerprint\n    fcfp_list = []    \n    for fcpc in range(124):\n        data[\"fcpc\" + str(fcpc)] = 0\n        fcfp_list.append(\"fcpc\" + str(fcpc))\n    fcpc_x = data[\"rd_form\"].apply(lambda x: np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124, useFeatures=True)))\n    fcpc_vector_lists = list(itertools.chain(*fcpc_x))\n    data.loc[:, fcfp_list] = np.array(fcpc_vector_lists).reshape(len(data),124)\n    \n    ecfp_list = []\n    for ecpc in range(124):\n        data[\"ecpc\" + str(ecpc)] = 0\n        ecfp_list.append(\"ecpc\" + str(ecpc))\n    ecpc_x = data[\"rd_form\"].apply(lambda x: np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124)))\n    ecpc_vector_lists = list(itertools.chain(*ecpc_x))\n    data.loc[:, ecfp_list] = np.array(ecpc_vector_lists).reshape(len(data),124)\n    \n    # mol2vec\n    m2v_list = []\n    data['sentence'] = data['rd_form'].apply(lambda x: mol2alt_sentence(x, radius=2))  \n    for m2v_idx in range(300):\n        data[\"m2v\" + str(m2v_idx)] = 0\n        m2v_list.append(\"m2v\" + str(m2v_idx))\n    m2v = [DfVec(x) for x in sentences2vec(data['sentence'], mol_model, unseen='UNK')]\n    m2v = np.array([x.vec for x in m2v])\n    data.loc[:,m2v_list] = m2v.reshape(len(data),300)\n    data.drop([\"sentence\"], inplace=True, axis=1)\n    \n    min_max_scaler = MinMaxScaler()\n    m2v_idx_list = []\n    data['sentence'] = data['rd_form'].apply(lambda x: mol2alt_sentence(x, radius=2))\n    for m2v_idx in range(300):\n        data[\"m2v\" + str(m2v_idx)] = 0\n        m2v_idx_list.append(\"m2v\" + str(m2v_idx))\n    m2v_x = [DfVec(x) for x in sentences2vec(data['sentence'], mol_model, unseen='UNK')]\n    m2v_list = [x.vec for x in m2v_x]\n    m2v_vector_lists = list(itertools.chain(*m2v_list))\n    m2v_array = np.array(m2v_vector_lists).reshape(len(data),300)\n    m2v_minmax = min_max_scaler.fit_transform(m2v_array)\n    data.loc[:, m2v_idx_list] = m2v_minmax\n    data = data.drop(['sentence'], axis=1)\n    \n#     data['sentence'] = data['rd_form'].apply(lambda x: MolSentence(mol2alt_sentence(x, 1)), axis=1)\n#     m2v = [DfVec(x) for x in sentences2vec(data['sentence'], mol_model, unseen='UNK')]\n#     m2v = np.array([x.vec for x in m2v])\n#     m2v = pd.DataFrame(m2v)\n#     m2v.columns = [\"m2v_\"+str(x) for x in m2v.columns]\n    \n    return data\n\n\ndef cal_auc(prob, labels):\n    f = list(zip(prob, labels))\n    rank = [values2 for values1, values2 in sorted(f, key=lambda x: x[0])]\n    rankList = [i + 1 for i in range(len(rank)) if rank[i] == 1]\n    posNum = 0\n    negNum = 0\n    for i in range(len(labels)):\n        if (labels[i] == 1):\n            posNum += 1\n        else:\n            negNum += 1\n    auc = (sum(rankList) - (posNum * (posNum + 1)) / 2) / (posNum * negNum)\n    return auc\n\n# imputate, normalize, discretize and train-test split the data\ndef split(train):\n    train = train.drop([\"rd_form\"], axis=1)\n    Y_train = train[\"ACTIVE\"]\n    X_train = train.drop([\"ACTIVE\"], axis=1)\n    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=1)\n    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n    scaler = MinMaxScaler()\n    kbd = KBinsDiscretizer(n_bins=10, encode=\"ordinal\")\n    train_index = x_train.index\n    x_train = imp_mean.fit_transform(x_train)\n    x_train[:, [1, 2]] = scaler.fit_transform(x_train[:, [1, 2]])\n    x_train[:, [1, 2]] = kbd.fit_transform(x_train[:, [1, 2]])\n    x_train = pd.DataFrame(x_train, columns=X_train.columns, index=train_index)\n    test_index = x_val.index\n    x_val = imp_mean.transform(x_val)\n    x_val[:, [1, 2]] = scaler.transform(x_val[:, [1, 2]])\n    x_val[:, [1, 2]] = kbd.transform(x_val[:, [1, 2]])\n    x_val = pd.DataFrame(x_val, columns=X_train.columns, index=test_index)\n    return x_train, x_val, y_train, y_val\n\ndef get_train_labels(train):\n    train = train.drop([\"rd_form\"], axis=1)\n    y_train = train[\"ACTIVE\"]\n    x_train = train.drop([\"ACTIVE\"], axis=1)\n    x_train_columns = x_train.columns\n    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n    scaler = MinMaxScaler()\n    kbd = KBinsDiscretizer(n_bins=10, encode=\"ordinal\")\n    train_index = x_train.index\n    x_train = imp_mean.fit_transform(x_train)\n    x_train[:, [1, 2]] = scaler.fit_transform(x_train[:, [1, 2]])\n    x_train[:, [1, 2]] = kbd.fit_transform(x_train[:, [1, 2]])\n    x_train = pd.DataFrame(x_train, columns=x_train_columns, index=train_index)\n\n    return x_train, y_train\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_all_feature(dataframe):\n    data = dataframe.copy()\n    \n    mol_model = word2vec.Word2Vec.load('/kaggle/input/assignment4datas/model_300dim.pkl')\n    \n    data[\"num_atom\"] = data[\"rd_form\"].apply(lambda x:x.GetNumAtoms())\n    data[\"mol_dr\"] = data[\"rd_form\"].apply(lambda x: d.CalcExactMolWt(x))\n    data[\"COO\"] = data[\"rd_form\"].apply(lambda x: f.fr_Al_COO(x))\n    \n    data[\"OH\"] = data[\"rd_form\"].apply(lambda x: f.fr_Al_OH(x))\n    data[\"ArN\"] = data[\"rd_form\"].apply(lambda x: f.fr_ArN(x))\n    data[\"halogen\"] = data[\"rd_form\"].apply(lambda x: f.fr_halogen(x))\n    data[\"aliphatic_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAliphaticRings(x))\n    data[\"aromatic_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAromaticRings(x))\n    \n    \n    # fingerprint\n    fcfp_list = []    \n    for fcpc in range(124):\n        data[\"fcpc\" + str(fcpc)] = 0\n        fcfp_list.append(\"fcpc\" + str(fcpc))\n    fcpc_x = data[\"rd_form\"].apply(lambda x: np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124, useFeatures=True)))\n    fcpc_vector_lists = list(itertools.chain(*fcpc_x))\n    data.loc[:, fcfp_list] = np.array(fcpc_vector_lists).reshape(len(data),124)\n    \n    ecfp_list = []\n    for ecpc in range(124):\n        data[\"ecpc\" + str(ecpc)] = 0\n        ecfp_list.append(\"ecpc\" + str(ecpc))\n    ecpc_x = data[\"rd_form\"].apply(lambda x: np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124)))\n    ecpc_vector_lists = list(itertools.chain(*ecpc_x))\n    data.loc[:, ecfp_list] = np.array(ecpc_vector_lists).reshape(len(data),124)\n    \n    # mol2vec\n    m2v_list = []\n    data['sentence'] = data['rd_form'].apply(lambda x: mol2alt_sentence(x, radius=2))  \n    for m2v_idx in range(300):\n        data[\"m2v\" + str(m2v_idx)] = 0\n        m2v_list.append(\"m2v\" + str(m2v_idx))\n    m2v = [DfVec(x) for x in sentences2vec(data['sentence'], mol_model, unseen='UNK')]\n    m2v = np.array([x.vec for x in m2v])\n    data.loc[:,m2v_list] = m2v.reshape(len(data),300)\n    data.drop([\"sentence\"], inplace=True, axis=1)\n    \n\n    \n    return data\n\ndef get_ecfp_feature(dataframe):\n    data = dataframe.copy()\n    \n    mol_model = word2vec.Word2Vec.load('/kaggle/input/assignment4datas/model_300dim.pkl')\n    \n    data[\"num_atom\"] = data[\"rd_form\"].apply(lambda x:x.GetNumAtoms())\n    data[\"mol_dr\"] = data[\"rd_form\"].apply(lambda x: d.CalcExactMolWt(x))\n    data[\"COO\"] = data[\"rd_form\"].apply(lambda x: f.fr_Al_COO(x))\n    \n    data[\"OH\"] = data[\"rd_form\"].apply(lambda x: f.fr_Al_OH(x))\n    data[\"ArN\"] = data[\"rd_form\"].apply(lambda x: f.fr_ArN(x))\n    data[\"halogen\"] = data[\"rd_form\"].apply(lambda x: f.fr_halogen(x))\n    data[\"aliphatic_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAliphaticRings(x))\n    data[\"aromatic_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAromaticRings(x))\n    \n    ecfp_list = []\n    for ecpc in range(124):\n        data[\"ecpc\" + str(ecpc)] = 0\n        ecfp_list.append(\"ecpc\" + str(ecpc))\n    ecpc_x = data[\"rd_form\"].apply(lambda x: np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124)))\n    ecpc_vector_lists = list(itertools.chain(*ecpc_x))\n    data.loc[:, ecfp_list] = np.array(ecpc_vector_lists).reshape(len(data),124)\n    \n    return data\n\ndef get_fcfp_feature(dataframe):\n    data = dataframe.copy()\n    \n    mol_model = word2vec.Word2Vec.load('/kaggle/input/assignment4datas/model_300dim.pkl')\n    \n    data[\"num_atom\"] = data[\"rd_form\"].apply(lambda x:x.GetNumAtoms())\n    data[\"mol_dr\"] = data[\"rd_form\"].apply(lambda x: d.CalcExactMolWt(x))\n    data[\"COO\"] = data[\"rd_form\"].apply(lambda x: f.fr_Al_COO(x))\n    \n    data[\"OH\"] = data[\"rd_form\"].apply(lambda x: f.fr_Al_OH(x))\n    data[\"ArN\"] = data[\"rd_form\"].apply(lambda x: f.fr_ArN(x))\n    data[\"halogen\"] = data[\"rd_form\"].apply(lambda x: f.fr_halogen(x))\n    data[\"aliphatic_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAliphaticRings(x))\n    data[\"aromatic_ring_count\"] = data[\"rd_form\"].apply(lambda x: Lipinski.NumAromaticRings(x))\n    \n    \n    # fingerprint\n    fcfp_list = []    \n    for fcpc in range(124):\n        data[\"fcpc\" + str(fcpc)] = 0\n        fcfp_list.append(\"fcpc\" + str(fcpc))\n    fcpc_x = data[\"rd_form\"].apply(lambda x: np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124, useFeatures=True)))\n    fcpc_vector_lists = list(itertools.chain(*fcpc_x))\n    data.loc[:, fcfp_list] = np.array(fcpc_vector_lists).reshape(len(data),124)\n    \n    return data\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binary_bayes(x_train, x_val,  y_train, y_val):\n    model = BernoulliNB()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef guassian_bayes(x_train, x_val,  y_train, y_val):\n    model = GaussianNB()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef multi_bayes(x_train, x_val,  y_train, y_val):\n    model = MultinomialNB()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef decision_tree(x_train, x_val,  y_train, y_val):\n    model = DecisionTreeClassifier()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef mlp(x_train, x_val,  y_train, y_val):\n    model = MLPClassifier()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef random_forest(x_train, x_val,  y_train, y_val):\n    model = RandomForestClassifier(max_depth=30, n_estimators=400, class_weight='balanced_subsample') \n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n#     auc = cal_auc(prediction[:, 1], np.array(y_val))\n    from sklearn.metrics import roc_auc_score\n    auc = roc_auc_score(np.array(y_val), np.array(prediction[:, 1]))\n\n    return model, auc, prediction\n\n\ndef light_boost(x_train, x_val,  y_train, y_val):\n    model = lgb.LGBMClassifier()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction\n\n\ndef extreme_boost(x_train, x_val,  y_train, y_val):\n    model = xgb.XGBClassifier()\n    model.fit(x_train, y_train)\n    prediction = model.predict_proba(x_val)\n    auc = cal_auc(prediction[:, 1], np.array(y_val))\n    return model, auc, prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train_path = \"/kaggle/input/assignment4datas/training_smiles.csv\"\ntest_path = \"/kaggle/input/assignment4datas/test_smiles.csv\"\npre_train = load_data(train_path)\npre_test = load_data(test_path)\n# data = get_smile(pre_train).sample(n=10, random_state=2)\ndata = get_smile(pre_train)\n\ntrain = get_feature(data)\n\n# train = get_feature(get_smile(pre_train))\n# test = get_feature(get_smile(pre_test))\n### Split\nx_train, x_val, y_train, y_val = split(train)\nlb, lb_auc, lb_prediction = light_boost(x_train,x_val,y_train, y_val)\neb, eb_auc, en_prediction = extreme_boost(x_train,x_val,y_train, y_val)\nrf, rf_auc, rf_prediction = random_forest(x_train,x_val,y_train, y_val)\nprint(lb_auc)\nprint(eb_auc)\nprint(rf_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = get_smile(pre_train)\ntrain = get_feature(data)\n# train = get_feature(get_smile(pre_train))\n# test = get_feature(get_smile(pre_test))\n### Split\nx_train, x_val, y_train, y_val = split(train)\nlb_params = {\n    'learning_rate': 0.2,\n    'num_leaves': 60,\n    'n_estimators': 250,\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'subsample': 0.8,\n    'reg_alpha': 0.1,\n    'reg_lambda': 0,\n}\nlb, lb_auc, lb_prediction = light_boost(x_train,x_val,y_train, y_val)\nrf, rf_auc, rf_prediction = random_forest(x_train,x_val,y_train, y_val)\neb, eb_auc, en_prediction = extreme_boost(x_train,x_val,y_train, y_val)\n\nupdate_model = lgb.LGBMClassifier(**lb_params)\nupdate_model.fit(x_train, y_train)\nupdate_prediction = update_model.predict_proba(x_val)\nupdate_auc = cal_auc(update_prediction[:, 1], np.array(y_val))\nprint(lb_auc)\nprint(rf_auc)\nprint(eb_auc)\nprint(update_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, random_state=42, shuffle=False)\n# lb_params = {\n#     'learning_rate': [0.005],\n#     'num_leaves': [30, 40, 50, 60],\n#     'n_estimators': [75, 150, 225],\n#     'boosting_type': ['gbdt'],\n#     'objective': ['binary'],\n#     'subsample': [0.7, 0.75, 0.8],\n#     'reg_alpha': [0, 0.1, 0.2],\n#     'reg_lambda': [0, 0.1, 0.2],\n# }\n\n# xgb_params = {\n#     'learning_rate': [0.01, 0.1, 0.2],\n#     'n_estimators': [300, 400],\n#     'gamma': [0],\n#     'max_depth': [24, 36],\n#     'subsample': [0.8],\n#     'min_child_weight': [1],\n# }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fcfp_data = load_data(\"/kaggle/input/assignment4datas/train_fcfp .csv\")\nm2v_data = load_data(\"/kaggle/input/assignment4datas/train_m2v.csv\")\necfp_data = load_data(\"/kaggle/input/assignment4datas/train_ecfp.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\ndef kFoldAUC(model, X_train, y_train):\n    kf = KFold(n_splits=5, random_state=42, shuffle=False)\n    rf = RandomForestClassifier(class_weight='balanced_subsample', max_depth=30,\n                       n_estimators=400)\n    print(cross_val_score(rf, X_train, y_train, cv=kf, scoring='roc_auc'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fcfp or ecfp\ndef rf_auc_1(dataframe):\n    data = dataframe.copy()\n    x_train, x_val, y_train, y_val = split(data)\n    rf, rf_auc, rf_prediction = random_forest(x_train,x_val,y_train, y_val)\n    \n    print(\"kFold predict ...\")\n    x_train, y_train = get_train_labels(data)\n    kFoldAUC(rf,x_train, y_train)\n    return rf, rf_auc, rf_prediction\n\n# m2v\ndef rf_auc_m2v(dataframe):\n    data = dataframe.copy()\n    x_train, x_val, y_train, y_val = split(data)\n    \n    min_max_scaler = MinMaxScaler()\n    # normalize the m2v columns\n    m2v_array_x_train=x_train.loc[:, [\"m2v\"+str(i) for i in range(300)]]\n    x_train.loc[:, [\"m2v\"+str(i) for i in range(300)]] = min_max_scaler.fit_transform(m2v_array_x_train)\n    m2v_array_x_val=x_val.loc[:, [\"m2v\"+str(i) for i in range(300)]]\n    x_val.loc[:, [\"m2v\"+str(i) for i in range(300)]] = min_max_scaler.transform(m2v_array_x_val)\n\n    rf, rf_auc, rf_prediction = random_forest(x_train,x_val,y_train, y_val)\n    return rf, rf_auc, rf_prediction\n\n# fcfp + ecfp\ndef rf_auc_2(dataframe1, dataframe2):\n    data1 = dataframe1.copy()\n    data2 = dataframe2.copy()\n    ecfp_list = [\"ecpc\"+str(i) for i in range(124)]\n    data1[ecfp_list] = np.array(data2.loc[:,ecfp_list])\n    \n    x_train, x_val, y_train, y_val = split(data1)\n    rf, rf_auc, rf_prediction = random_forest(x_train,x_val,y_train, y_val)\n    return rf, rf_auc, rf_prediction\n\n# fcfp + ecfp + m2v\ndef rf_auc_3(dataframe1, dataframe2, dataframe3):\n    data1 = dataframe1.copy()\n    data2 = dataframe2.copy()\n    data3 = dataframe3.copy()\n    fcfp_list = [\"fcpc\"+str(i) for i in range(124)]\n    ecfp_list = [\"ecpc\"+str(i) for i in range(124)]\n    data3[fcfp_list] = np.array(data1.loc[:, fcfp_list])\n    data3[ecfp_list] = np.array(data2.loc[:, ecfp_list])\n    \n    min_max_scaler = MinMaxScaler()\n    x_train, x_val, y_train, y_val = split(data3)\n    \n    # normalize the m2v columns\n    m2v_array_x_train=x_train.loc[:, [\"m2v\"+str(i) for i in range(300)]]\n    x_train.loc[:, [\"m2v\"+str(i) for i in range(300)]] = min_max_scaler.fit_transform(m2v_array_x_train)\n\n    m2v_array_x_val=x_val.loc[:, [\"m2v\"+str(i) for i in range(300)]]\n    x_val.loc[:, [\"m2v\"+str(i) for i in range(300)]] = min_max_scaler.transform(m2v_array_x_val)\n    \n\n\n    rf, rf_auc, rf_prediction = random_forest(x_train, x_val, y_train, y_val)\n    return rf, rf_auc, rf_prediction\n\n\ndef rf_auc_final(dataframe1, dataframe2, dataframe3):\n    data1 = dataframe1.copy()\n    data2 = dataframe2.copy()\n    data3 = dataframe3.copy()\n    fcfp_list = [\"fcpc\"+str(i) for i in range(124)]\n    ecfp_list = [\"ecpc\"+str(i) for i in range(124)]\n    data3[fcfp_list] = np.array(data1.loc[:, fcfp_list])\n    data3[ecfp_list] = np.array(data2.loc[:, ecfp_list])\n    \n    print(\"get x_train and y_train ...\")\n    x_train, y_train = get_train_labels_final(data3)\n    print(\"kFold predict ...\")\n    kFoldAUC(rf, x_train, y_train)\n\ndef get_train_labels_final(train):\n    train = train.drop([\"rd_form\"], axis=1)\n    y_train = train[\"ACTIVE\"]\n    x_train = train.drop([\"ACTIVE\"], axis=1)\n    x_train_columns = x_train.columns\n    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n    scaler = MinMaxScaler()\n    kbd = KBinsDiscretizer(n_bins=10, encode=\"ordinal\")\n    train_index = x_train.index\n    \n    m2v_list = [\"m2v\"+str(i) for i in range(300)]\n    \n    x_train = imp_mean.fit_transform(x_train)\n    x_train[:, [1, 2]+m2v_list] = scaler.fit_transform(x_train[:, [1, 2]])\n    x_train[:, [1, 2]+m2v_list] = kbd.fit_transform(x_train[:, [1, 2]])\n    x_train = pd.DataFrame(x_train, columns=x_train_columns, index=train_index)\n\n    return x_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_auc_final(fcfp_data,ecfp_data, m2v_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test fingerprint(True)\nrf, rf_auc, rf_prediction = rf_auc_1(fcfp_data)\nprint(rf_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test fingerprint(False)\nrf, rf_auc, rf_prediction = rf_auc_1(ecfp_data)\nprint(rf_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test m2v\nrf, rf_auc, rf_prediction = rf_auc_m2v(m2v_data)\nprint(rf_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test fingerprint(True+False)\nrf, rf_auc, rf_prediction = rf_auc_2(fcfp_data, ecfp_data)\nprint(rf_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test fingerprint(True+False) + m2v\nrf, rf_auc, rf_prediction = rf_auc_3(fcfp_data, ecfp_data, m2v_data)\nprint(rf_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, random_state=42, shuffle=False)\ngrid_search = GridSearchCV(lb, param_grid=lb_params, cv=kf, scoring='roc_auc')\ngrid_search.fit(x_train, y_train)\nbest_params = grid_search.best_params_\nupdate_model = lgb.LGBMClassifier(**best_params)\nupdate_model.fit(x_train, y_train)\nupdate_prediction = update_model.predict_proba(x_val)\nupdate_auc = cal_auc(update_prediction[:, 1], np.array(y_val))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}